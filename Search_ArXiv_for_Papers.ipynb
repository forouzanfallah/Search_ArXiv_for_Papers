{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDy4IQzT6b0KKtVh6X7ZlH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/forouzanfallah/Search_ArXiv_for_Papers/blob/main/Search_ArXiv_for_Papers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install arxiv\n"
      ],
      "metadata": {
        "id": "4jNtPP29Ns3R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d8440b1-d9c9-4516-94e3-1be0032a7b82"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting arxiv\n",
            "  Downloading arxiv-2.1.0-py3-none-any.whl (11 kB)\n",
            "Collecting feedparser==6.0.10 (from arxiv)\n",
            "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m829.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from arxiv) (2.31.0)\n",
            "Collecting sgmllib3k (from feedparser==6.0.10->arxiv)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->arxiv) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->arxiv) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->arxiv) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->arxiv) (2024.2.2)\n",
            "Building wheels for collected packages: sgmllib3k\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6049 sha256=d4fc80efb75bb3cbfffa2b9b286c09f5aae8455c927f293c74f75b26576d39e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
            "Successfully built sgmllib3k\n",
            "Installing collected packages: sgmllib3k, feedparser, arxiv\n",
            "Successfully installed arxiv-2.1.0 feedparser-6.0.10 sgmllib3k-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import arxiv\n",
        "import datetime\n",
        "\n",
        "class ArxivSearcher:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the arXiv searcher with a client.\"\"\"\n",
        "        self.client = arxiv.Client()\n",
        "\n",
        "    def search(self, keywords, start_date, end_date, max_results=1000):\n",
        "        \"\"\"Search arXiv for papers matching the given keywords within the specified date range,\n",
        "        up to max_results after filtering by date, and include the submission date in the output.\"\"\"\n",
        "\n",
        "        # Format the search query\n",
        "        search_query = ' AND '.join(f'all:\"{keyword}\"' for keyword in keywords)\n",
        "\n",
        "        # Format the dates\n",
        "        start = datetime.datetime.strptime(start_date, '%Y-%m-%d').date()\n",
        "        end = datetime.datetime.strptime(end_date, '%Y-%m-%d').date()\n",
        "\n",
        "        # Initialize an empty list to store filtered results\n",
        "        filtered_results = []\n",
        "\n",
        "        # Assume we fetch more initially to ensure we have enough results to filter through\n",
        "        initial_fetch = 100\n",
        "\n",
        "        # Perform search\n",
        "        search = arxiv.Search(\n",
        "            query=search_query,\n",
        "            max_results=initial_fetch,  # Fetch more results initially\n",
        "            sort_by=arxiv.SortCriterion.SubmittedDate,\n",
        "            sort_order=arxiv.SortOrder.Descending\n",
        "        )\n",
        "\n",
        "        # Fetch results and filter\n",
        "        for result in self.client.results(search):\n",
        "            # Check if the result is within the specified date range\n",
        "            if start <= result.published.date() <= end:\n",
        "                filtered_results.append(result)\n",
        "                # Break if we have enough filtered results\n",
        "                if len(filtered_results) == max_results:\n",
        "                    break\n",
        "\n",
        "        # Display the filtered results\n",
        "        for result in filtered_results:\n",
        "            print(f\"Title: {result.title}\\nLink: {result.entry_id}\\nSubmitted Date: {result.published.strftime('%Y-%m-%d')}\\n\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wSgG6WwALYXO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    searcher = ArxivSearcher()\n",
        "    keywords = ['visual text']  # Add your keywords here\n",
        "    start_date = '2024-01-01'  # Start date in YYYY-MM-DD format\n",
        "    end_date = '2024-03-29'  # End date in YYYY-MM-DD format\n",
        "    max_results = 105  # Specify the maximum number of results to return after filtering\n",
        "    searcher.search(keywords, start_date, end_date, max_results)"
      ],
      "metadata": {
        "id": "_3L1i0WL2FnT",
        "outputId": "c69117af-5f61-4754-83df-1bc62a7b8d70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: Refining Text-to-Image Generation: Towards Accurate Training-Free Glyph-Enhanced Image Generation\n",
            "Link: http://arxiv.org/abs/2403.16422v1\n",
            "Submitted Date: 2024-03-25\n",
            "\n",
            "Title: Glyph-ByT5: A Customized Text Encoder for Accurate Visual Text Rendering\n",
            "Link: http://arxiv.org/abs/2403.09622v1\n",
            "Submitted Date: 2024-03-14\n",
            "\n",
            "Title: UniCode: Learning a Unified Codebook for Multimodal Large Language Models\n",
            "Link: http://arxiv.org/abs/2403.09072v1\n",
            "Submitted Date: 2024-03-14\n",
            "\n",
            "Title: Answering Diverse Questions via Text Attached with Key Audio-Visual Clues\n",
            "Link: http://arxiv.org/abs/2403.06679v1\n",
            "Submitted Date: 2024-03-11\n",
            "\n",
            "Title: NPHardEval4V: A Dynamic Reasoning Benchmark of Multimodal Large Language Models\n",
            "Link: http://arxiv.org/abs/2403.01777v2\n",
            "Submitted Date: 2024-03-04\n",
            "\n",
            "Title: Towards Accurate Lip-to-Speech Synthesis in-the-Wild\n",
            "Link: http://arxiv.org/abs/2403.01087v1\n",
            "Submitted Date: 2024-03-02\n",
            "\n",
            "Title: VIXEN: Visual Text Comparison Network for Image Difference Captioning\n",
            "Link: http://arxiv.org/abs/2402.19119v2\n",
            "Submitted Date: 2024-02-29\n",
            "\n",
            "Title: UniVS: Unified and Universal Video Segmentation with Prompts as Queries\n",
            "Link: http://arxiv.org/abs/2402.18115v1\n",
            "Submitted Date: 2024-02-28\n",
            "\n",
            "Title: Visual Text Meets Low-level Vision: A Comprehensive Survey on Visual Text Processing\n",
            "Link: http://arxiv.org/abs/2402.03082v1\n",
            "Submitted Date: 2024-02-05\n",
            "\n",
            "Title: NFT1000: A Visual Text Dataset For Non-Fungible Token Retrieval\n",
            "Link: http://arxiv.org/abs/2402.16872v1\n",
            "Submitted Date: 2024-01-29\n",
            "\n",
            "Title: CoAVT: A Cognition-Inspired Unified Audio-Visual-Text Pre-Training Model for Multimodal Processing\n",
            "Link: http://arxiv.org/abs/2401.12264v2\n",
            "Submitted Date: 2024-01-22\n",
            "\n",
            "Title: DGL: Dynamic Global-Local Prompt Tuning for Text-Video Retrieval\n",
            "Link: http://arxiv.org/abs/2401.10588v1\n",
            "Submitted Date: 2024-01-19\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EwlArPVR2Tkq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}